// Copyright (c) 2025 hotflow2024
// Licensed under AGPL-3.0-or-later. See LICENSE for details.
// Commercial licensing available. See COMMERCIAL_LICENSE.md.
/**
 * Model Capability Registry â€” AI è°ƒåº¦ä¸­å¿ƒæ ¸å¿ƒç»„ä»¶ 1
 *
 * èŒè´£ï¼šæ ¹æ®æ¨¡å‹åç§°æŸ¥è¯¢ contextWindow å’Œ maxOutput é™åˆ¶ã€‚
 * ä¸‰å±‚æŸ¥æ‰¾ï¼ˆä¼˜å…ˆçº§é€’å‡ï¼‰ï¼š
 *   1. æŒä¹…åŒ–ç¼“å­˜ï¼ˆä» API é”™è¯¯ä¸­è‡ªåŠ¨å­¦åˆ°çš„çœŸå®é™åˆ¶ï¼‰
 *   2. é™æ€æ³¨å†Œè¡¨ï¼ˆå®˜æ–¹æ–‡æ¡£éªŒè¯è¿‡çš„å·²çŸ¥æ¨¡å‹ï¼‰
 *   3. _default ä¿å®ˆé»˜è®¤å€¼
 *
 * è®¾è®¡åŸåˆ™ï¼š
 *   - æŒ‰æ¨¡å‹åæŸ¥è¡¨ï¼Œä¸æŒ‰ URL â€” memefast ä»£ç†çš„æ¨¡å‹å’Œç›´è¿ä¸€æ ·
 *   - prefix åŒ¹é…æŒ‰é•¿åº¦é™åº â€” é¿å…çŸ­å‰ç¼€è¯¯åŒ¹é…æ›´å…·ä½“çš„æ¨¡å‹
 *   - ä»…è¦†ç›– text/chat æ¨¡å‹ â€” å›¾åƒ/è§†é¢‘/éŸ³é¢‘ä¸èµ° callChatAPI
 *   - ä¿å®ˆé»˜è®¤å€¼ â€” æœªçŸ¥æ¨¡å‹å®å¯å¤šåˆ†æ‰¹ä¹Ÿä¸æ’é™åˆ¶
 */

// ==================== Types ====================

export interface ModelLimits {
  /** æ¨¡å‹æœ€å¤§è¾“å…¥ä¸Šä¸‹æ–‡çª—å£ï¼ˆtokensï¼‰ */
  contextWindow: number;
  /** æ¨¡å‹æœ€å¤§è¾“å‡º token æ•°ï¼ˆmax_tokens å‚æ•°ä¸Šé™ï¼‰ */
  maxOutput: number;
}

/** ä» API 400 é”™è¯¯ä¸­å‘ç°çš„æ¨¡å‹é™åˆ¶ï¼ˆæŒä¹…åŒ–åˆ° localStorageï¼‰ */
export interface DiscoveredModelLimits {
  maxOutput?: number;
  contextWindow?: number;
  /** å‘ç°æ—¶é—´æˆ³ */
  discoveredAt: number;
}

// ==================== Static Registry ====================

/**
 * é™æ€æ³¨å†Œè¡¨ â€” ä»…å«å®˜æ–¹æ–‡æ¡£éªŒè¯è¿‡çš„æ•°æ®
 *
 * æ•°æ®æ¥æºï¼š
 *   - DeepSeek: https://api-docs.deepseek.com/quick_start/pricing (V3.2 = 128K context)
 *   - GLM: https://bigmodel.cn/pricing + å¤šæ–¹éªŒè¯ (4.7 = 200K ctx / 128K output)
 *   - Gemini: https://ai.google.dev/gemini-api/docs/models + OCI docs (2.5 = 1M ctx / 65K output)
 *   - å…¶ä»–: ä¿å®ˆå€¼ï¼Œæ ‡æ³¨"ä¿å®ˆ"
 *
 * âš ï¸ memefast ä¸Šçš„åŒåæ¨¡å‹ä½¿ç”¨ç›¸åŒé™åˆ¶ã€‚æ–°å¢æ¨¡å‹åº”æŸ¥é˜…å®˜æ–¹æ–‡æ¡£åæ·»åŠ ï¼Œä¸å¯é çŒœæµ‹ã€‚
 */
const STATIC_REGISTRY: Record<string, ModelLimits> = {
  // ==================== DeepSeek ç³»åˆ— ====================
  // DeepSeek-V3.2: 128K context limit
  // memefast æ¨¡å‹å: deepseek-v3, deepseek-v3.2, deepseek-r1
  'deepseek-v3':            { contextWindow: 128000,   maxOutput: 8192   },
  'deepseek-v3.2':          { contextWindow: 128000,   maxOutput: 8192   },
  'deepseek-chat':          { contextWindow: 128000,   maxOutput: 8192   },
  'deepseek-r1':            { contextWindow: 128000,   maxOutput: 16384  },
  'deepseek-reasoner':      { contextWindow: 128000,   maxOutput: 16384  },

  // ==================== æ™ºè°± GLM ç³»åˆ— ====================
  'glm-4.7':                { contextWindow: 200000,   maxOutput: 128000 },
  'glm-4.6v':               { contextWindow: 128000,   maxOutput: 8192   }, // ä¿å®ˆ
  'glm-4.5-flash':          { contextWindow: 128000,   maxOutput: 8192   }, // ä¿å®ˆ

  // ==================== Google Gemini ç³»åˆ— ====================
  'gemini-2.5-flash':       { contextWindow: 1048576,  maxOutput: 65536  },
  'gemini-2.5-pro':         { contextWindow: 1048576,  maxOutput: 65536  },
  'gemini-3-flash-preview': { contextWindow: 1048576,  maxOutput: 65536  }, // æ²¿ç”¨ 2.5 è§„æ ¼
  'gemini-3-pro-preview':   { contextWindow: 1048576,  maxOutput: 65536  },
  'gemini-2.0-flash':       { contextWindow: 1048576,  maxOutput: 8192   },

  // ==================== å…¶ä»–æ¨¡å‹ï¼ˆä¿å®ˆå€¼ï¼‰ ====================
  'kimi-k2':                { contextWindow: 128000,   maxOutput: 8192   },
  'qwen3-max':              { contextWindow: 128000,   maxOutput: 8192   },
  'qwen3-max-preview':      { contextWindow: 128000,   maxOutput: 8192   },
  'minimax-m2.1':           { contextWindow: 128000,   maxOutput: 8192   },

  // ==================== é€šç”¨ prefix è§„åˆ™ ====================
  // æ³¨æ„ï¼šprefix åŒ¹é…æŒ‰é•¿åº¦é™åºæ‰§è¡Œï¼Œé•¿ key ä¼˜å…ˆ
  'deepseek-':              { contextWindow: 128000,   maxOutput: 8192   },
  'gemini-':                { contextWindow: 1048576,  maxOutput: 65536  },
  'glm-':                   { contextWindow: 128000,   maxOutput: 8192   },
  'claude-':                { contextWindow: 200000,   maxOutput: 8192   },
  'gpt-':                   { contextWindow: 128000,   maxOutput: 16384  },
  'doubao-':                { contextWindow: 32000,    maxOutput: 4096   },

  // ==================== é»˜è®¤å€¼ ====================
  '_default':               { contextWindow: 32000,    maxOutput: 4096   },
};

// Pre-sort keys by length descending for prefix matching
// Exclude '_default' from prefix search
const SORTED_KEYS = Object.keys(STATIC_REGISTRY)
  .filter(k => k !== '_default')
  .sort((a, b) => b.length - a.length);

// ==================== Discovery Cache Access ====================

// These are injected at runtime by the store (avoids circular dependency)
let _getDiscoveredLimits: ((model: string) => DiscoveredModelLimits | undefined) | null = null;
let _setDiscoveredLimits: ((model: string, limits: Partial<DiscoveredModelLimits>) => void) | null = null;

/**
 * æ³¨å…¥æŒä¹…åŒ–ç¼“å­˜çš„è¯»å†™å‡½æ•°ï¼ˆç”± api-config-store åœ¨åˆå§‹åŒ–æ—¶è°ƒç”¨ï¼‰
 * è¿™ç§æ¨¡å¼é¿å…äº† model-registry â†” api-config-store çš„å¾ªç¯ä¾èµ–
 */
export function injectDiscoveryCache(
  getter: (model: string) => DiscoveredModelLimits | undefined,
  setter: (model: string, limits: Partial<DiscoveredModelLimits>) => void,
): void {
  _getDiscoveredLimits = getter;
  _setDiscoveredLimits = setter;
}

// ==================== Core Lookup ====================

/**
 * æŸ¥è¯¢æ¨¡å‹çš„ contextWindow å’Œ maxOutput é™åˆ¶
 *
 * ä¸‰å±‚æŸ¥æ‰¾ï¼š
 *   1. æŒä¹…åŒ–ç¼“å­˜ï¼ˆError-driven Discovery å­¦åˆ°çš„çœŸå®é™åˆ¶ï¼‰
 *   2. é™æ€æ³¨å†Œè¡¨ï¼ˆç²¾ç¡®åŒ¹é… â†’ prefix åŒ¹é…ï¼Œprefix æŒ‰é•¿åº¦é™åºï¼‰
 *   3. _default
 */
export function getModelLimits(modelName: string): ModelLimits {
  const m = modelName.toLowerCase();

  // Layer 1: æŒä¹…åŒ–ç¼“å­˜ï¼ˆæœ€å‡†ç¡®ï¼Œä» API é”™è¯¯ä¸­å­¦åˆ°çš„çœŸå®å€¼ï¼‰
  if (_getDiscoveredLimits) {
    const discovered = _getDiscoveredLimits(m);
    if (discovered) {
      const staticFallback = lookupStatic(m);
      return {
        contextWindow: discovered.contextWindow ?? staticFallback.contextWindow,
        maxOutput: discovered.maxOutput ?? staticFallback.maxOutput,
      };
    }
  }

  // Layer 2 + 3: é™æ€æ³¨å†Œè¡¨ â†’ _default
  return lookupStatic(m);
}

/**
 * ä»…ä»é™æ€æ³¨å†Œè¡¨æŸ¥æ‰¾ï¼ˆä¸æŸ¥ç¼“å­˜ï¼‰
 */
function lookupStatic(modelNameLower: string): ModelLimits {
  // ç²¾ç¡®åŒ¹é…
  if (STATIC_REGISTRY[modelNameLower]) {
    return STATIC_REGISTRY[modelNameLower];
  }

  // prefix åŒ¹é…ï¼ˆé•¿åº¦é™åºä¿è¯æœ€å…·ä½“çš„å…ˆå‘½ä¸­ï¼‰
  for (const key of SORTED_KEYS) {
    if (modelNameLower.startsWith(key)) {
      return STATIC_REGISTRY[key];
    }
  }

  // å…œåº•
  return STATIC_REGISTRY['_default'];
}

// ==================== Error-driven Discovery ====================

/**
 * ä» API 400 é”™è¯¯æ¶ˆæ¯ä¸­è§£ææ¨¡å‹é™åˆ¶
 *
 * è¦†ç›–ä¸»æµ API çš„é”™è¯¯æ ¼å¼ï¼š
 *   - DeepSeek: "Invalid max_tokens value, the valid range of max_tokens is [1, 8192]"
 *   - OpenAI:   "maximum context length is 128000 tokens ... you requested 150000 tokens"
 *   - æ™ºè°±:     "max_tokens must be less than or equal to 8192"
 *   - é€šç”¨:     "max_tokens ... 8192" ç­‰å„ç§å˜ä½“
 *
 * @returns è§£æå‡ºçš„é™åˆ¶ï¼ˆå¯èƒ½åªæœ‰ maxOutput æˆ– contextWindow æˆ–ä¸¤è€…éƒ½æœ‰ï¼‰ï¼Œ
 *          å¦‚æœæ­£åˆ™æœªåŒ¹é…åˆ°ä»»ä½•æ•°å€¼åˆ™è¿”å› nullï¼ˆä¼˜é›…é™çº§ï¼Œä¸ä¼šæ­»å¾ªç¯ï¼‰
 */
export function parseModelLimitsFromError(errorText: string): Partial<DiscoveredModelLimits> | null {
  const result: Partial<DiscoveredModelLimits> = {};
  let found = false;

  // --- è§£æ max_tokens / maxOutput ---
  // Pattern 1: "valid range of max_tokens is [1, 8192]"
  const rangeMatch = errorText.match(/valid\s+range.*?\[\s*\d+\s*,\s*(\d+)\s*\]/i);
  if (rangeMatch) {
    result.maxOutput = parseInt(rangeMatch[1], 10);
    found = true;
  }

  // Pattern 2: "max_tokens must be less than or equal to 8192" / "max_tokens ... <= 8192"
  if (!found) {
    const lteMatch = errorText.match(/max_tokens.*?(?:less than or equal to|<=|ä¸è¶…è¿‡|ä¸Šé™ä¸º?)\s*(\d{3,6})/i);
    if (lteMatch) {
      result.maxOutput = parseInt(lteMatch[1], 10);
      found = true;
    }
  }

  // Pattern 3: Generic fallback â€” "max_tokens" é™„è¿‘çš„æ•°å­—
  if (!found) {
    const genericMatch = errorText.match(/max_tokens.*?\b(\d{3,6})\b/i);
    if (genericMatch) {
      result.maxOutput = parseInt(genericMatch[1], 10);
      found = true;
    }
  }

  // --- è§£æ context window ---
  // Pattern: "context length is 128000" / "maximum context length is 128000 tokens"
  const ctxMatch = errorText.match(/context.*?length.*?(\d{4,7})/i);
  if (ctxMatch) {
    result.contextWindow = parseInt(ctxMatch[1], 10);
    found = true;
  }

  // Pattern: "maximum ... 128000 tokens" (OpenAI é£æ ¼)
  if (!result.contextWindow) {
    const maxTokensCtx = errorText.match(/maximum.*?(\d{4,7})\s*tokens/i);
    if (maxTokensCtx) {
      result.contextWindow = parseInt(maxTokensCtx[1], 10);
      found = true;
    }
  }

  if (!found) return null;

  result.discoveredAt = Date.now();
  return result;
}

/**
 * å°†å‘ç°çš„é™åˆ¶å†™å…¥æŒä¹…åŒ–ç¼“å­˜
 * @returns true å¦‚æœæˆåŠŸå†™å…¥ï¼Œfalse å¦‚æœç¼“å­˜æœªæ³¨å…¥
 */
export function cacheDiscoveredLimits(
  modelName: string,
  limits: Partial<DiscoveredModelLimits>,
): boolean {
  if (!_setDiscoveredLimits) return false;
  _setDiscoveredLimits(modelName.toLowerCase(), limits);
  console.log(
    `[ModelRegistry] ğŸ§  å·²å­¦ä¹  ${modelName} çš„é™åˆ¶:`,
    limits.maxOutput != null ? `maxOutput=${limits.maxOutput}` : '',
    limits.contextWindow != null ? `contextWindow=${limits.contextWindow}` : '',
  );
  return true;
}

// ==================== Utility ====================

/**
 * Token ä¼°ç®—ï¼ˆä¿å®ˆç®—æ³•ï¼‰
 *
 * ä½¿ç”¨ å­—ç¬¦æ•°/1.5 ä½œä¸ºä¿å®ˆä¸Šé™ï¼š
 *   - ä¸­æ–‡: 1 token â‰ˆ 0.6~1.0 æ±‰å­—ï¼Œ/1.5 ç›¸å½“äºæ”¾å¤§ä¼°ç®—ï¼ˆåå®‰å…¨ï¼‰
 *   - è‹±æ–‡/æ ‡ç‚¹/JSON: 1 token â‰ˆ 3~4 å­—ç¬¦ï¼Œ/1.5 ä¹Ÿåå®‰å…¨
 *   - å®å¯é«˜ä¼° token æ•°ï¼ˆå¤šåˆ†æ‰¹ï¼‰ï¼Œä¹Ÿä¸ä½ä¼°ï¼ˆæ’é™åˆ¶ï¼‰
 *   - ä¸å¼•å…¥ tiktoken ç­‰é‡å‹åº“ï¼Œé¿å…å‰ç«¯ WASM å…¼å®¹æ€§å’Œä½“ç§¯é—®é¢˜
 */
export function estimateTokens(text: string): number {
  return Math.ceil(text.length / 1.5);
}

/**
 * æ™ºèƒ½æˆªæ–­æ–‡æœ¬ï¼Œä¸åœ¨å¥å­æˆ–æ®µè½ä¸­é—´åˆ‡æ–­
 * é¿å…æˆªæ–­å¯¼è‡´ JSON ç»“æ„æŸåæˆ– AI ç†è§£æ··ä¹±
 *
 * @param text åŸå§‹æ–‡æœ¬
 * @param maxLength æœ€å¤§å­—ç¬¦æ•°
 * @param hint æˆªæ–­æ—¶è¿½åŠ çš„æç¤ºåç¼€ï¼ˆå¸®åŠ© AI ç†è§£ä¿¡æ¯ä¸å®Œæ•´ï¼Œå‡å°‘å¹»è§‰ï¼‰
 */
export function safeTruncate(
  text: string,
  maxLength: number,
  hint: string = '...[åç»­å†…å®¹å·²æˆªæ–­]',
): string {
  if (text.length <= maxLength) return text;

  // ä¸º hint é¢„ç•™ç©ºé—´
  const budget = maxLength - hint.length;
  if (budget <= 0) return text.slice(0, maxLength);

  const sliced = text.slice(0, budget);

  // ä¼˜å…ˆåœ¨æ¢è¡Œå¤„æˆªæ–­ï¼ˆä¿ç•™å®Œæ•´æ®µè½ï¼‰
  const lastNewline = sliced.lastIndexOf('\n');
  if (lastNewline > budget * 0.8) {
    return sliced.slice(0, lastNewline) + hint;
  }

  // å…¶æ¬¡åœ¨ä¸­æ–‡/è‹±æ–‡å¥æœ«æˆªæ–­ï¼ˆä¿ç•™å®Œæ•´å¥å­ï¼‰
  const lastSentenceEnd = Math.max(
    sliced.lastIndexOf('ã€‚'),
    sliced.lastIndexOf('ï¼'),
    sliced.lastIndexOf('ï¼Ÿ'),
    sliced.lastIndexOf('. '),
  );
  if (lastSentenceEnd > budget * 0.8) {
    return sliced.slice(0, lastSentenceEnd + 1) + hint;
  }

  return sliced + hint;
}
